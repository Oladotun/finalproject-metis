{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_dates(d1, d2):\n",
    "    date1 = datetime.datetime.strptime(d1.replace(\",\",\"\").strip(), '%Y-%m-%d')\n",
    "    date2 = datetime.datetime.strptime(d2.replace(\",\",\"\").strip(), '%Y-%m-%d')\n",
    "    return abs(date2-date1).days\n",
    "def timedatelinesplit(newKick, columnName):\n",
    "    newKick[columnName+\"_datetime\"] = newKick[columnName].apply(lambda x: datetime.datetime.fromtimestamp(float(x)).strftime('%Y-%m-%d , %H:%M:%S, %A'))\n",
    "    new = newKick[columnName+\"_datetime\"].str.split(\",\", n = 2, expand = True) \n",
    "    newKick[columnName+\"_date\"] = new[0]\n",
    "    newKick[columnName+\"_time\"] = new[1]\n",
    "    timeDayArray =  []\n",
    "    for hours in new[1]:\n",
    "        hours = hours.strip().split(\":\")\n",
    "\n",
    "        timeOfDay = \"\"\n",
    "        if int(hours[0]) in [12,13,14,15]:\n",
    "            timeOfDay = \"Afternoon\"\n",
    "            timeDayArray.append(timeOfDay)\n",
    "        elif hours[0] in [16,17,18,19,20]:\n",
    "            timeOfDay = \"Evening\"\n",
    "            timeDayArray.append(timeOfDay)\n",
    "        elif hours[0] in [20,21,22,23,24]:\n",
    "            timeOfDay = \"Night\"\n",
    "            timeDayArray.append(timeOfDay)\n",
    "        else:\n",
    "            timeOfDay = \"Morning\"\n",
    "            timeDayArray.append(timeOfDay)\n",
    "        \n",
    "    newKick[columnName+\"_moment\"] = timeDayArray\n",
    "    newKick[columnName+\"_day\"] = new[2]\n",
    "    \n",
    "    newKick = newKick.drop(columns = [columnName, columnName+\"_datetime\"])\n",
    "    \n",
    "    return newKick\n",
    "def getDfValues(df,names):\n",
    "    return df[names[0]], df[[names[1]]]\n",
    "def stateReturn(state):\n",
    "    if state == 'successful':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kick = pd.read_csv(\"Kickstarter001.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop non needed columns\n",
    "newKick = kick.drop(columns = [\"is_backing\",\"is_starred\",\"static_usd_rate\",\"urls\",\n",
    "                     \"source_url\",\"currency_trailing_code\",\"id\",\"slug\", \"current_currency\",\n",
    "                     \"currency\",\"profile\",\"photo\",\"permissions\",\"created_at\",\n",
    "                     \"usd_pledged\",\"usd_type\",\"converted_pledged_amount\",\n",
    "                     \"currency_symbol\",\"disable_communication\",\"friends\",\n",
    "                     \"fx_rate\",\"is_starrable\"\n",
    "                     ])\n",
    "\n",
    "## Get only for USA\n",
    "newKick = newKick[newKick[\"country\"] == \"US\"]\n",
    "newKick = newKick.apply(lambda row: row[newKick['state'].isin(['successful','failed'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namesArray = []\n",
    "slugArray = []\n",
    "categoryNameSlugArray = []\n",
    "for row in newKick[\"category\"]:\n",
    "    rowDict = ast.literal_eval(row)\n",
    "    namesArray.append(rowDict[\"name\"])\n",
    "    \n",
    "    slugArray.append(rowDict[\"slug\"].split(\"/\")[0])\n",
    "    categoryNameSlugArray.append(rowDict[\"name\"] + \" \"+rowDict[\"slug\"].split(\"/\")[0])\n",
    "newKick[\"category_name\"] = namesArray\n",
    "newKick[\"category_slug\"] = slugArray\n",
    "newKick[\"category_name_slug\"] = categoryNameSlugArray\n",
    "newKick = newKick.drop(columns = [\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creatorArray = []\n",
    "creatorNameArray = []   \n",
    "for row in newKick[\"creator\"]:\n",
    "    rowDict = str(row)\n",
    "    rowArray = rowDict.split(\":\")\n",
    "    rowOneArray = rowArray[1].split(\",\")\n",
    "    creatorArray.append(rowOneArray[0])\n",
    "    rowTwoArray = rowArray[2].split(\",\")\n",
    "    creatorNameArray.append(rowTwoArray[0])\n",
    "newKick[\"creator_id\"] = creatorArray\n",
    "newKick[\"creator_name\"] = creatorNameArray\n",
    "\n",
    "newKick = newKick.drop(columns = [\"creator\"])\n",
    "\n",
    "locationArray = []\n",
    "locationNameArray = []  \n",
    "for row in newKick[\"location\"]:\n",
    "    if str(row) != 'nan': \n",
    "        rowDict = str(row)\n",
    "        rowArray = rowDict.split(\",\")\n",
    "        rowOneArray = rowArray[1].split(\":\")\n",
    "        rowTwoArray = rowArray[9].split(\":\")\n",
    "        \n",
    "        locationArray.append(rowOneArray[1].replace('\\\"',\"\").strip() + \" \"+ rowTwoArray[1].replace('\\\"',\"\").strip())\n",
    "    else:\n",
    "        locationArray.append(\"help\")\n",
    "\n",
    "newKick[\"city_state\"] = locationArray\n",
    "newKick = newKick.drop(columns = [\"location\", \"country\"])    \n",
    "newKick = timedatelinesplit(newKick, \"deadline\")\n",
    "newKick = timedatelinesplit(newKick, \"launched_at\")\n",
    "newKick[\"goal_pledged_diff\"] = newKick[\"pledged\"] - newKick[\"goal\"]\n",
    "newKick[\"duration_for_days\"] = newKick[[\"deadline_date\",\"launched_at_date\"]].apply(lambda x: diff_dates(x[0],x[1]), axis = 1)\n",
    "newKick[\"staff_pick\"] = newKick[\"staff_pick\"]\n",
    "\n",
    "\n",
    "### EDA GroupBys\n",
    "#category = newKick[newKick[\"state\"]==\"successful\"].groupby(\"category_slug\").count()\n",
    "category = newKick[newKick[\"state\"]==\"successful\"].groupby(\"category_slug\").count()\n",
    "cleanedUpKick = newKick.drop(columns=[\"backers_count\",\"blurb\",\"name\",\"pledged\",\"state_changed_at\",\n",
    "                      \"deadline_date\",\"deadline_time\",\"launched_at_date\", \"creator_name\" , \"category_name\",\"category_slug\",\"goal_pledged_diff\",\"spotlight\"])\n",
    "cols = ['goal', 'duration_for_days']\n",
    "subset_df = newKick[cols]\n",
    "\n",
    "#Standard Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "scaled_df = ss.fit_transform(subset_df)\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=cols)\n",
    "\n",
    "\n",
    "# Category Slug\n",
    "cleanedUpKick['staff_pick'] = cleanedUpKick['staff_pick'].astype(int)\n",
    "cleanedUpKick['state'] = cleanedUpKick['state'].apply(lambda x:stateReturn(x))\n",
    "cleanedWithKickTime = pd.get_dummies(cleanedUpKick, columns=[\"category_name_slug\",\"city_state\",\"launched_at_day\",\"launched_at_moment\"])\n",
    "cleanedWithKickTime[[\"goal\",\"duration_for_days\"]] = scaled_df\n",
    "cleanedWithKickTime.dropna(axis='rows',inplace=True)\n",
    "X = cleanedWithKickTime.drop(columns=[\"state\",\"deadline_moment\",\"deadline_day\",\"launched_at_time\",\"creator_id\"])\n",
    "Y = cleanedWithKickTime[\"state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=101)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "result = model.fit(X_train, y_train)\n",
    "\n",
    "from sklearn import metrics\n",
    "prediction_test = model.predict(X_test)\n",
    "print (metrics.accuracy_score(y_test, prediction_test))\n",
    "\n",
    "## To get the weights of all the variables\n",
    "weights = pd.Series(model.coef_[0],index=X.columns.values)\n",
    "weightSorted = weights.sort_values(ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.preprocessing.text import Tokenizer\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "#from keras.layers import SpatialDropout1D\n",
    "\n",
    "## Neural Network Logistic Regression\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=1053, init = 'uniform' ,output_dim=527, activation = 'relu'))\n",
    "model.add(Dense(output_dim=527, activation = 'relu'))\n",
    "model.add(Dense(output_dim = 1, activation='sigmoid'))\n",
    "#model.add(SpatialDropout1D(0.2))\n",
    "\n",
    "#model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "#model.add(Dense(18, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=256, epochs=epochs, \n",
    "              validation_data=(X_test, y_test))\n",
    "hidden_features = model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metis",
   "language": "python",
   "name": "metis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
